{
	"title": "ChatCompletionInput",
	"$id": "/inference/schemas/chat-completion/input.json",
	"$schema": "http://json-schema.org/draft-06/schema#",
	"description": "Inputs for ChatCompletion inference",
	"type": "object",
	"properties": {
		"messages": {
			"type": "array",
			"title": "ChatCompletionInputMessage",
			"items": {
				"type": "object",
				"properties": {
					"role": {
						"$ref": "#/defs/Role"
					},
					"content": {
						"type": "string",
						"description": "The content of the message."
					},
					"name": {
						"type": "string",
						"description": "The name of the message. Provides the model information to differentiate between participants of the same role."
					}
				},
				"required": ["role", "content"]
			}
		},
		"frequency_penalty": {
			"type": "number",
			"description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim."
		},
		"presence_penalty": {
			"type": "number",
			"description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics."
		},
		"max_tokens": {
			"type": "integer",
			"description": "The maximum number of tokens that can be generated in the chat completion."
		},
		"seed": {
			"type": "integer",
			"description": "The random sampling seed."
		},
		"stop": {
			"oneOf": [{ "type": "string" }, { "type": "array", "items": { "type": "string" } }],
			"title": "ChatCompletionInputStopReason",
			"description": "Stop generating tokens if a stop token is generated."
		},
		"stream": {
			"type": "boolean",
			"description": "If set, partial message deltas will be sent."
		},
		"temperature": {
			"type": "number",
			"description": "The value used to modulate the logits distribution."
		},
		"tools": {
			"type": "array",
			"items": {
				"$ref": "#/defs/Tool"
			},
			"description": "The tools to use for generation."
		},
		"tool_choice": {
			"type": "string",
			"description": "The tool to use for generation."
		},
		"top_p": {
			"type": "number",
			"description": "If set to < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation."
		}
	},
	"defs": {
		"Role": {
			"oneOf": [{ "const": "assistant" }, { "const": "system" }, { "const": "user" }],
			"title": "ChatCompletionMessageRole",
			"description": "The role of the message author."
		},
		"Tool": {
			"title": "ChatCompletionTool",
			"description": "The tool to use for generation.",
			"properties": {
				"type": {
					"type": "string",
					"description": "The type of tool to use."
				},
				"function": {
					"type": "object",
					"description": "The function of the tool to use."
				}
			}
		}
	},
	"required": ["messages"]
}
